{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script requires a .csv file containing the minimum distances for valid MOF-guest structure configurations and their energies obtained with low parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms, Atom\n",
    "from ase.visualize import view\n",
    "from ase.io import read, write\n",
    "from ase.build import mx2, add_adsorbate\n",
    "from ase.constraints import FixAtoms\n",
    "from ase.build import surface\n",
    "from ase.data.colors import jmol_colors\n",
    "from IPython import display\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin, pairwise_distances_argmin_min\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.manifold import MDS\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from ase.collections import g2\n",
    "from ase.build import molecule\n",
    "\n",
    "###scikitlearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "##plot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = os.getcwd()\n",
    "\n",
    "#directories = ['alcohol_bencilico', 'benceno', 'benzaldehido',\n",
    "               #'CO', 'CO2', 'H2S']\n",
    "directories = ['H2S']\n",
    "for i in directories:\n",
    "    dir = main +'/'+ i\n",
    "    print(dir)\n",
    "    os.chdir(dir)\n",
    "    os.mkdir('par_geom_energia')  ### directory where the test structure will be saved\n",
    "    os.chdir('output')\n",
    "    df = pd.read_csv('descriptors.csv',  index_col=0)  ### this file containf minimum distances from every valid structure\n",
    "    \n",
    "    ##Limpieza de datos para quitar outliers por medio de Multivariate Outlier Analysys: ###\n",
    "\n",
    "    # Here we separate the independent variables for their analysis\n",
    "    # ==============================================================================\n",
    "    X = df[['Energy', 'd_O-Sc0', 'd_O-Sc1', 'd_O-Sc2', 'd_O-Sc3']]\n",
    "\n",
    "    # Definition and training of the IsolationForest Model for Anomaly detection\n",
    "    # Pleasenote that this is a unsupervised model and hence thereis no objective way to train it\n",
    "    # The following is a Naive set of parammeters\n",
    "    # ==============================================================================\n",
    "    modelo_isof = IsolationForest(\n",
    "                n_estimators  = 1000,\n",
    "                max_samples   ='auto',\n",
    "                contamination = 0.1,\n",
    "                random_state  = 0)\n",
    "\n",
    "    modelo_isof.fit(X)\n",
    "\n",
    "\n",
    "    # Prediction from the Anomaly Detection Model\n",
    "    # ==============================================================================\n",
    "    X['anomaly'] = modelo_isof.predict(X)    # Anomaly prediction| 1:Ok | -1:Anomaly\n",
    "\n",
    "\n",
    "    df_clean = df.loc[X['anomaly']==1]\n",
    "    df_clean_index = list(df_clean.index)\n",
    "\n",
    "\n",
    "    ####Normaling dataframe columns ###\n",
    "    min_max_scaler = preprocessing.MinMaxScaler() #normalizing data\n",
    "    mat = min_max_scaler.fit_transform(df_clean[['Energy', 'd_O-Sc0', 'd_O-Sc1', 'd_O-Sc2', 'd_O-Sc3']])\n",
    "    #comb = list(combinations([0,1,2,3],2))\n",
    "    df_normalize = pd.DataFrame(mat)\n",
    "\n",
    "\n",
    "    # Reset index to ignore old indexes \n",
    "    df1_selected = df_clean['No. Structure'].reset_index(drop=True)\n",
    "    df2_selected = df_normalize.reset_index(drop=True)\n",
    "    result = pd.concat([df1_selected, df2_selected], axis=1)\n",
    "    result = result.rename(columns={0: 'Energy', 1: 'd_O-Sc0', 2: 'd_O-Sc1', 3: 'd_O-Sc2', 4: 'd_O-Sc3'})\n",
    "\n",
    "\n",
    "    ##Starts clustering with normalized data ####\n",
    "    colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00']\n",
    "    lowenergy = result.sort_values(by=['Energy'])\n",
    "    ind = lowenergy.index.values\n",
    "\n",
    "\n",
    "    #MDS Method \n",
    "    mds = MDS(n_components=2,\n",
    "                random_state=0,\n",
    "                metric=True,\n",
    "                n_init=4,\n",
    "                max_iter=300,\n",
    "                verbose=0,\n",
    "                eps=0.001,\n",
    "                dissimilarity='euclidean',\n",
    "                n_jobs=1)\n",
    "    pos = mds.fit(df_normalize).embedding_\n",
    "\n",
    "    clusters = [3]\n",
    "    for nc in clusters:\n",
    "        km = KMeans(n_clusters=nc,\n",
    "                       init='k-means++',\n",
    "                       n_init=10,\n",
    "                       max_iter=300,\n",
    "                       random_state=0)\n",
    "        km.fit(df_normalize)\n",
    "\n",
    "        # We want to have the same colors for the same cluster from the MiniBatchKMeans and the KMeans algorithm. Let's pair the cluster centers per closest one.\n",
    "        k_means_cluster_centers = km.cluster_centers_  #centros de los clusters \n",
    "        k_means_labels = pairwise_distances_argmin(df_normalize, k_means_cluster_centers) #Compute minimum distances between one point and a set of points\n",
    "        closest, dist = pairwise_distances_argmin_min(k_means_cluster_centers, df_normalize) #return data indexes closest to centroides and the distances\n",
    "        print('Los indices de los puntos m√°s cercanos al centroidese de cada cluster son: ', closest)\n",
    "        a = k_means_labels.tolist()\n",
    "\n",
    "\n",
    "        #Plotting clusters \n",
    "    fig =  plt.figure(figsize=(10, 8))\n",
    "    for k, col in zip(range(nc), colors):\n",
    "            my_members = k_means_labels == k\n",
    "             #cluster_center = pos[-nc:,:][k]\n",
    "            plt.scatter(pos[my_members, 0], pos[my_members, 1], c=col, s=16, label=k+1, edgecolor='none', alpha=0.4)\n",
    "            plt.scatter(pos[my_members, 0].mean(), pos[my_members, 1].mean(), c=col, marker='*', s=150, edgecolor='k')\n",
    "    #plt.scatter(pos[ind[0], 0], pos[ind[0], 1], c='k', s=40, label='Energy')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.savefig('clusters_{}.png'.format(i)) ## se guardan graficas en output\n",
    "\n",
    "    # copying structurs closest to the centroid of every cluster to our directory.\n",
    "    for j in closest:\n",
    "        str_close_centro = result.iloc[j]\n",
    "        os.system('cp -rf conf_{} ../par_geom_energia'.format(int(str_close_centro['No. Structure'])))\n",
    "\n",
    "    os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
